{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers tags :\n",
      "\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfl-h2\"><span id=\"From_today.27s_featured_list\"></span><span class=\"mw-headline\" id=\"From_today's_featured_list\">From today's featured list</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\"><span>Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\"><span>Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-variants-label\"><span>Variants</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\"><span>Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-cactions-label\"><span>More</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\"><span>Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\"><span>Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\"><span>Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\"><span>Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\"><span>In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\"><span>Languages</span>\n",
      "</h3>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#Ques_1\n",
    "\n",
    "url=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "Soup=BeautifulSoup(url.content)\n",
    "headers=Soup.find_all(['h1','h2','h3'])\n",
    "print('Headers tags :',*headers,sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year_of_release</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Movie_name Rating Year_of_release\n",
       "Rank                                                                      \n",
       "1.                         The Shawshank Redemption    9.3          (1994)\n",
       "2.                                    The Godfather    9.2          (1972)\n",
       "3.                                  The Dark Knight    9.0          (2008)\n",
       "4.                           The Godfather: Part II    9.0          (1974)\n",
       "5.                                     12 Angry Men    9.0          (1957)\n",
       "6.    The Lord of the Rings: The Return of the King    8.9          (2003)\n",
       "7.                                     Pulp Fiction    8.9          (1994)\n",
       "8.                                 Schindler's List    8.9          (1993)\n",
       "9.                                        Inception    8.8          (2010)\n",
       "10.                                      Fight Club    8.8          (1999)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release).\n",
    "\n",
    "#Ques_2\n",
    "\n",
    "imdb=requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')\n",
    "imdb\n",
    "imdb.content\n",
    "Soup=BeautifulSoup(imdb.content)\n",
    "Soup\n",
    "\n",
    "name=Soup.find_all('h3', class_=\"lister-item-header\")\n",
    "name\n",
    "series_name=[]\n",
    "for i in name:\n",
    "    for j in i.find_all('a'):\n",
    "        series_name.append(j.text.replace('\\n',''))\n",
    "series_name\n",
    "\n",
    "rank=Soup.find_all('span' ,class_=\"lister-item-index unbold text-primary\")\n",
    "Rank=[]\n",
    "for k in rank:\n",
    "    Rank.append(k.text)\n",
    "Rank\n",
    "\n",
    "rating=Soup.find_all('div', class_=\"inline-block ratings-imdb-rating\")\n",
    "Rating=[]\n",
    "for x in rating:\n",
    "    Rating.append(x.text.replace('\\n',''))\n",
    "Rating\n",
    "\n",
    "year=Soup.find_all('span' ,class_=\"lister-item-year text-muted unbold\")\n",
    "Year=[]\n",
    "for l in year:\n",
    "    Year.append(l.text)\n",
    "Year\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Rank']=Rank[:10]\n",
    "df['Movie_name']=series_name[:10]\n",
    "df['Rating']=Rating[:10]\n",
    "df['Year_of_release']=Year[:10]\n",
    "df.set_index('Rank',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDB_rating</th>\n",
       "      <th>Year_of_release</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nayakan</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anbe Sivam</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pariyerum Perumal</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C/o Kancharapalem</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golmaal</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apur Sansar</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manichitrathazhu</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kireedam</th>\n",
       "      <td>8.5</td>\n",
       "      <td>(1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natsamrat</th>\n",
       "      <td>8.4</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pather Panchali</th>\n",
       "      <td>8.4</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  IMDB_rating Year_of_release\n",
       "Movie_name                                   \n",
       "Nayakan                   8.5          (1987)\n",
       "Anbe Sivam                8.5          (2003)\n",
       "Pariyerum Perumal         8.5          (2018)\n",
       "C/o Kancharapalem         8.5          (2018)\n",
       "Golmaal                   8.5          (1979)\n",
       "Apur Sansar               8.5          (1959)\n",
       "Manichitrathazhu          8.5          (1993)\n",
       "Kireedam                  8.5          (1989)\n",
       "Natsamrat                 8.4          (2016)\n",
       "Pather Panchali           8.4          (1955)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release).\n",
    "\n",
    "#Ques_3\n",
    "\n",
    "new=requests.get('https://www.imdb.com/india/top-rated-indian-movies/?sort=rk,asc&mode=simple&page=1')\n",
    "new\n",
    "new.content\n",
    "Soup=BeautifulSoup(new.content)\n",
    "Soup\n",
    "\n",
    "Name=Soup.find_all('td', class_='titleColumn')\n",
    "name=[]\n",
    "for i in Name:\n",
    "    for k in i.find_all('a'):\n",
    "        name.append(k.text.replace('\\n',''))\n",
    "name\n",
    "\n",
    "Rating=Soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "rating=[]\n",
    "for j in Rating:\n",
    "    rating.append(j.text.replace('\\n',''))\n",
    "rating\n",
    "\n",
    "Year=Soup.find_all('span', class_=\"secondaryInfo\")\n",
    "year=[]\n",
    "for l in Year:\n",
    "    year.append(l.text)\n",
    "year\n",
    "\n",
    "\n",
    "DF=pd.DataFrame({})\n",
    "DF['Movie_name']=name[:10]\n",
    "DF['IMDB_rating']=rating[:10]\n",
    "DF['Year_of_release']=year[:10]\n",
    "DF.set_index('Movie_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seeing Ghosts</td>\n",
       "      <td>Kat Chow</td>\n",
       "      <td>Nonfiction / Memoir / Family &amp; Relationships</td>\n",
       "      <td>Like the experience of grief itself, Kat Chow’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Einstein</td>\n",
       "      <td>Torben Kuhlmann</td>\n",
       "      <td>Children's / Children's Picture Book</td>\n",
       "      <td>Author-illustrator Torben Kuhlmann explores th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Guide</td>\n",
       "      <td>Peter Heller</td>\n",
       "      <td>Fiction / Speculative Fiction / Thriller</td>\n",
       "      <td>The Guide is a glorious getaway in every sense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Maidens</td>\n",
       "      <td>Alex Michaelides, Louise Brealey, Kobna Holdbr...</td>\n",
       "      <td>Audio / Mystery &amp; Suspense / Suspense</td>\n",
       "      <td>Actors Louise Brealey and Kobna Holdbrook-Smit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Love Songs of W.E.B. Du Bois</td>\n",
       "      <td>Honorée Fanonne Jeffers</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>Honorée Fanonne Jeffers weaves an epic ancestr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Book name  \\\n",
       "1                       Seeing Ghosts   \n",
       "6                            Einstein   \n",
       "4                           The Guide   \n",
       "3                         The Maidens   \n",
       "5    The Love Songs of W.E.B. Du Bois   \n",
       "\n",
       "                                         Author name  \\\n",
       "1                                           Kat Chow   \n",
       "6                                    Torben Kuhlmann   \n",
       "4                                       Peter Heller   \n",
       "3  Alex Michaelides, Louise Brealey, Kobna Holdbr...   \n",
       "5                            Honorée Fanonne Jeffers   \n",
       "\n",
       "                                          Genre  \\\n",
       "1  Nonfiction / Memoir / Family & Relationships   \n",
       "6          Children's / Children's Picture Book   \n",
       "4      Fiction / Speculative Fiction / Thriller   \n",
       "3         Audio / Mystery & Suspense / Suspense   \n",
       "5                  Fiction / Historical Fiction   \n",
       "\n",
       "                                              Review  \n",
       "1  Like the experience of grief itself, Kat Chow’...  \n",
       "6  Author-illustrator Torben Kuhlmann explores th...  \n",
       "4  The Guide is a glorious getaway in every sense...  \n",
       "3  Actors Louise Brealey and Kobna Holdbrook-Smit...  \n",
       "5  Honorée Fanonne Jeffers weaves an epic ancestr...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’\n",
    "\n",
    "#Ques_4\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "new_book=requests.get('https://bookpage.com/reviews')\n",
    "new_book\n",
    "\n",
    "Soup=BeautifulSoup(new_book.content)\n",
    "\n",
    "book=Soup.find_all('h4' ,class_=\"italic\")\n",
    "book_name=[]\n",
    "for i in book:\n",
    "    for j in i.find_all('a'):\n",
    "        book_name.append(j.text.replace('★',''))\n",
    "book_name\n",
    "\n",
    "author=Soup.find_all('p' ,class_=\"sans bold\")\n",
    "author_name=[]\n",
    "for k in author:\n",
    "    author_name.append(k.text.replace('\\n',''))\n",
    "author_name\n",
    "\n",
    "genre=Soup.find_all('p', class_=\"genre-links hidden-phone\")\n",
    "Genre=[]\n",
    "for g in genre:\n",
    "    Genre.append(g.text.replace('\\n',''))\n",
    "Genre\n",
    "\n",
    "review=Soup.find_all('p',class_=\"excerpt\")\n",
    "Review=[]\n",
    "for r in review:\n",
    "    Review.append(r.text.replace('\\n',''))\n",
    "Review\n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Book name']=book_name\n",
    "df['Author name']=author_name\n",
    "df['Genre']=Genre\n",
    "df['Review']=Review\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "      <td>New Zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>3,244</td>\n",
       "      <td>116</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2,267</td>\n",
       "      <td>103</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>2,639</td>\n",
       "      <td>91</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>2,523</td>\n",
       "      <td>84</td>\n",
       "      <td>West Indies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>2,303</td>\n",
       "      <td>79</td>\n",
       "      <td>Sri Lanka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Matches Points Rating         Teams\n",
       "Position                                    \n",
       "1             17  2,054    121   New Zealand\n",
       "2             32  3,793    119       England\n",
       "3             28  3,244    116     Australia\n",
       "4             32  3,624    113         India\n",
       "5             22  2,267    103  South Africa\n",
       "6             27  2,524     93      Pakistan\n",
       "7             29  2,639     91    Bangladesh\n",
       "8             30  2,523     84   West Indies\n",
       "9             29  2,303     79     Sri Lanka\n",
       "10            17  1,054     62   Afghanistan"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "#iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "#Ques_5\n",
    "\n",
    "#i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "url=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "Soup=BeautifulSoup(url.content)\n",
    "Soup\n",
    "\n",
    "pos=Soup.find_all('td' ,class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "Pos=[]\n",
    "for p in pos:\n",
    "    Pos.append(p.text.replace('\\n',''))\n",
    "Pos\n",
    "\n",
    "team=Soup.find_all('td' ,class_=\"table-body__cell rankings-table__team\")\n",
    "Team=[]\n",
    "for t in team:\n",
    "    team1=t.text.replace('\\n','')\n",
    "    team2=team1.replace('ENG','')\n",
    "    team3=team2.replace('AUS','')\n",
    "    team4=team3.replace('IND','')\n",
    "    team5=team4.replace('SA','')\n",
    "    team6=team5.replace('PAK','')\n",
    "    team7=team6.replace('BAN','')\n",
    "    team8=team7.replace('WI','')\n",
    "    team9=team8.replace('SL','')\n",
    "    team10=team9.replace('AFG','')\n",
    "    Team.append(team10)\n",
    "Team\n",
    "\n",
    "matches=Soup.find_all('td' ,class_=\"table-body__cell u-center-text\")\n",
    "Matches=[]\n",
    "Points_2=[]\n",
    "for m in range(len(matches)):\n",
    "    if m%2 ==0:\n",
    "        Matches.append(matches[m].text)\n",
    "    else:\n",
    "        Points_2.append(matches[m].text)\n",
    "Matches\n",
    "\n",
    "rating=Soup.find_all('td' ,class_=\"table-body__cell u-text-right rating\")\n",
    "Ratings=[]\n",
    "for m in rating:\n",
    "    Ratings.append(m.text)\n",
    "Ratings\n",
    "\n",
    "# points=Soup.find_all('td' ,class_=\"table-body__cell u-center-text\")\n",
    "# Points=[]\n",
    "# for p in points:\n",
    "    \n",
    "# Points\n",
    "\n",
    "Team1=Soup.find('span' ,class_=\"u-hide-phablet\")\n",
    "Team_1=Team1.text\n",
    "\n",
    "Points1=Soup.find('td' ,class_=\"rankings-block__banner--points\")\n",
    "Points_1=Points1.text.replace('873','').strip()\n",
    "\n",
    "Match1=Soup.find('td' ,class_=\"rankings-block__banner--matches\")\n",
    "Match_1=Match1.text.replace('\\n','').strip()\n",
    "\n",
    "Rating1=Soup.find('td' ,class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Rating_1=Rating1.text.replace('\\n','').strip()\n",
    "Rating_1\n",
    "\n",
    "Pos1=Soup.find('td', class_=\"rankings-block__banner--pos\")\n",
    "Pos_1=Pos1.text\n",
    "Pos_1\n",
    "\n",
    "DF1=pd.DataFrame({'Position':Pos[:9],'Teams':Team[:9],'Matches':Matches[:9],'Points':Points_2[:9],'Rating':Ratings[:9]})\n",
    "DF1\n",
    "\n",
    "d1={'Position':[Pos_1],'Teams':[Team_1],'Matches':[Match_1],'Points':[Points_1],'Rating':[Rating_1]}\n",
    "df1=pd.DataFrame(data=d1)\n",
    "df1\n",
    "\n",
    "new_df1=pd.concat([df1,DF1])\n",
    "new_df1.set_index('Position',inplace=True)\n",
    "new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Babar Azam</th>\n",
       "      <td>873</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virat Kohli</th>\n",
       "      <td>844</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rohit Sharma</th>\n",
       "      <td>813</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ross Taylor</th>\n",
       "      <td>801</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Finch</th>\n",
       "      <td>779</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonny Bairstow</th>\n",
       "      <td>775</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David Warner</th>\n",
       "      <td>762</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quinton de Kock</th>\n",
       "      <td>758</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shai Hope</th>\n",
       "      <td>758</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kane Williamson</th>\n",
       "      <td>754</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Rating Team\n",
       "Player Name                \n",
       "Babar Azam         873  PAK\n",
       "Virat Kohli        844  IND\n",
       "Rohit Sharma       813  IND\n",
       "Ross Taylor        801   NZ\n",
       "Aaron Finch        779  AUS\n",
       "Jonny Bairstow     775  ENG\n",
       "David Warner       762  AUS\n",
       "Quinton de Kock    758   SA\n",
       "Shai Hope          758   WI\n",
       "Kane Williamson    754   NZ"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ques_5\n",
    "#2.0\n",
    "\n",
    "#odi batsman ranking\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page\n",
    "page.content\n",
    "Soup=BeautifulSoup(page.content)\n",
    "Soup.prettify\n",
    "table=Soup.find_all('td' ,class_=\"table-body__cell name\")\n",
    "\n",
    "Name=[]\n",
    "for n in table:\n",
    "    for j in n.find_all('a'):\n",
    "        Name.append(j.text.replace('\\n',''))\n",
    "Name\n",
    "\n",
    "team=Soup.find_all('span' ,class_=\"table-body__logo-text\")\n",
    "Team=[]\n",
    "for t in team:\n",
    "    Team.append(t.text.strip())\n",
    "Team\n",
    "\n",
    "rating=Soup.find_all('td' ,class_=\"table-body__cell u-text-right rating\")\n",
    "Rating=[]\n",
    "for r in rating:\n",
    "    Rating.append(r.text)\n",
    "Rating\n",
    "\n",
    "DF=pd.DataFrame({'Player Name':Name,'Team':Team,'Rating':Rating})\n",
    "\n",
    "name1=Soup.find('div' ,class_=\"rankings-block__banner--name\")\n",
    "Name1=name1.text\n",
    "\n",
    "team1=Soup.find('div' ,class_=\"rankings-block__banner--nationality\")\n",
    "Team1=team1.text.replace('873','').strip()\n",
    "\n",
    "rating1=Soup.find('div' ,class_=\"rankings-block__banner--rating\")\n",
    "Rating1=rating1.text\n",
    "\n",
    "d={'Player Name':[Name1],'Team':[Team1],'Rating':[Rating1]}\n",
    "df=pd.DataFrame(data=d)\n",
    "new_df=pd.concat([df,DF])\n",
    "new_df.set_index('Player Name',inplace=True)\n",
    "new_df[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trent Boult</th>\n",
       "      <td>737</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Josh Hazlewood</th>\n",
       "      <td>709</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mujeeb Ur Rahman</th>\n",
       "      <td>708</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris Woakes</th>\n",
       "      <td>700</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mehedi Hasan</th>\n",
       "      <td>692</td>\n",
       "      <td>BAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matt Henry</th>\n",
       "      <td>691</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jasprit Bumrah</th>\n",
       "      <td>679</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchell Starc</th>\n",
       "      <td>652</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakib Al Hasan</th>\n",
       "      <td>650</td>\n",
       "      <td>BAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kagiso Rabada</th>\n",
       "      <td>648</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Rating Team\n",
       "Player Name                 \n",
       "Trent Boult         737   NZ\n",
       "Josh Hazlewood      709  AUS\n",
       "Mujeeb Ur Rahman    708  AFG\n",
       "Chris Woakes        700  ENG\n",
       "Mehedi Hasan        692  BAN\n",
       "Matt Henry          691   NZ\n",
       "Jasprit Bumrah      679  IND\n",
       "Mitchell Starc      652  AUS\n",
       "Shakib Al Hasan     650  BAN\n",
       "Kagiso Rabada       648   SA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ques_5\n",
    "#3.0\n",
    "\n",
    "#odi bowling ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page\n",
    "page.content\n",
    "Soup=BeautifulSoup(page.content)\n",
    "Soup.prettify\n",
    "table=Soup.find_all('td', class_=\"table-body__cell name\")\n",
    "Name=[]\n",
    "for n in table:\n",
    "    for j in n.find_all('a'):\n",
    "        Name.append(j.text.replace('\\n',''))\n",
    "Name\n",
    "team=Soup.find_all('td' ,class_=\"table-body__cell nationality-logo\")\n",
    "Team=[]\n",
    "for t in team:\n",
    "    Team.append(t.text.strip())\n",
    "Team\n",
    "rating=Soup.find_all('td' ,class_=\"table-body__cell u-text-right rating\")\n",
    "Rating=[]\n",
    "for r in rating:\n",
    "    Rating.append(r.text)\n",
    "Rating\n",
    "\n",
    "DF_1=pd.DataFrame({'Player Name':Name[9:18],'Team':Team[9:18],'Rating':Rating[9:18]})\n",
    "\n",
    "Name1=Soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "Name_1=Name1[1].text\n",
    "\n",
    "Team1=Soup.find_all('div' ,class_=\"rankings-block__banner--nationality\")\n",
    "Team_1=Team1[1].text.replace('\\n','').split()[0]\n",
    "\n",
    "Rating1=Soup.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "Rating_1=Rating1[1].text.replace('\\n','')\n",
    "\n",
    "d_1={'Player Name':[Name_1],'Team':[Team_1],'Rating':[Rating_1]}\n",
    "df_1=pd.DataFrame(data=d_1)\n",
    "new_df_1=pd.concat([df_1,DF_1])\n",
    "new_df_1.set_index('Player Name',inplace=True)\n",
    "\n",
    "new_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2,370</td>\n",
       "      <td>119</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>2,535</td>\n",
       "      <td>110</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "      <td>New Zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>1,427</td>\n",
       "      <td>84</td>\n",
       "      <td>West Indies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1,496</td>\n",
       "      <td>75</td>\n",
       "      <td>Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "      <td>Sri Lanka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Matches Points Rating         Teams\n",
       "Position                                    \n",
       "1             18  2,955    164     Australia\n",
       "2             20  2,370    119       England\n",
       "3             24  2,828    118  South Africa\n",
       "4             23  2,535    110         India\n",
       "5             21  1,947     93   New Zealand\n",
       "6             17  1,427     84   West Indies\n",
       "7             20  1,496     75      Pakistan\n",
       "8              5    306     61    Bangladesh\n",
       "9             11    519     47     Sri Lanka\n",
       "10             2     25     13       Ireland"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "# iii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "#Ques_6\n",
    "\n",
    "#i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "Women=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "Soup_1=BeautifulSoup(Women.content)\n",
    "Soup_1\n",
    "\n",
    "W_pos=Soup_1.find_all('td' ,class_=\"table-body__cell table-body__cell--position u-text-right\")\n",
    "Pos_W=[]\n",
    "for p in W_pos:\n",
    "    Pos_W.append(p.text)\n",
    "\n",
    "W_team=Soup_1.find_all('span' ,class_=\"u-hide-phablet\")\n",
    "Team_W=[]\n",
    "for t in W_team[1:10]:\n",
    "    Team_W.append(t.text)\n",
    "\n",
    "W_match=Soup_1.find_all('td' ,class_=\"table-body__cell u-center-text\")\n",
    "Matches_W=[]\n",
    "Points_W=[]\n",
    "for m in range(len(W_match)):\n",
    "    if m%2 ==0:\n",
    "        Matches_W.append(W_match[m].text)\n",
    "    else:\n",
    "        Points_W.append(W_match[m].text)\n",
    "\n",
    "W_rating=Soup_1.find_all('td' ,class_=\"table-body__cell u-text-right rating\")\n",
    "Ratings_W=[]\n",
    "for m in W_rating:\n",
    "    Ratings_W.append(m.text)\n",
    "\n",
    "W_Team1=Soup_1.find('span' ,class_=\"u-hide-phablet\")\n",
    "Team_1W=W_Team1.text\n",
    "\n",
    "W_Points1=Soup_1.find('td' ,class_=\"rankings-block__banner--points\")\n",
    "Points_1W=W_Points1.text.replace('\\n','').strip()\n",
    "\n",
    "W_Match1=Soup_1.find('td' ,class_=\"rankings-block__banner--matches\")\n",
    "Match_1W=W_Match1.text.replace('\\n','').strip()\n",
    "\n",
    "W_Rating1=Soup_1.find('td' ,class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Rating_1W=W_Rating1.text.replace('\\n','').strip()\n",
    "\n",
    "W_Pos1=Soup_1.find('td', class_=\"rankings-block__banner--pos\")\n",
    "Pos_1W=W_Pos1.text\n",
    "\n",
    "W_DF=pd.DataFrame({'Position':Pos_W,'Teams':Team_W,'Matches':Matches_W,'Points':Points_W,'Rating':Ratings_W})\n",
    "W_DF\n",
    "\n",
    "df_W={'Position':[Pos_1W],'Teams':[Team_1W],'Matches':[Match_1W],'Points':[Points_1W],'Rating':[Rating_1W]}\n",
    "df_W1=pd.DataFrame(data=df_W)\n",
    "df_W1\n",
    "\n",
    "new_df_W1=pd.concat([df_W1,W_DF])\n",
    "new_df_W1.set_index('Position',inplace=True)\n",
    "new_df_W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mithali Raj</th>\n",
       "      <td>762</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lizelle Lee</th>\n",
       "      <td>758</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alyssa Healy</th>\n",
       "      <td>756</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tammy Beaumont</th>\n",
       "      <td>754</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stafanie Taylor</th>\n",
       "      <td>736</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meg Lanning</th>\n",
       "      <td>723</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy Satterthwaite</th>\n",
       "      <td>715</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natalie Sciver</th>\n",
       "      <td>706</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smriti Mandhana</th>\n",
       "      <td>701</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laura Wolvaardt</th>\n",
       "      <td>683</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Rating Team\n",
       "Player Name                  \n",
       "Mithali Raj          762  IND\n",
       "Lizelle Lee          758   SA\n",
       "Alyssa Healy         756  AUS\n",
       "Tammy Beaumont       754  ENG\n",
       "Stafanie Taylor      736   WI\n",
       "Meg Lanning          723  AUS\n",
       "Amy Satterthwaite    715   NZ\n",
       "Natalie Sciver       706  ENG\n",
       "Smriti Mandhana      701  IND\n",
       "Laura Wolvaardt      683   SA"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ques_6\n",
    "#2.0\n",
    "\n",
    "#odi womens ranking\n",
    "\n",
    "page_new=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page_new\n",
    "page_new.content\n",
    "Soup=BeautifulSoup(page_new.content)\n",
    "Soup.prettify\n",
    "\n",
    "table_W=Soup.find_all('td' ,class_=\"table-body__cell name\")\n",
    "Name_W=[]\n",
    "for n in table_W[0:9]:\n",
    "    for j in n.find_all('a'):\n",
    "        Name_W.append(j.text.replace('\\n',''))\n",
    "        \n",
    "team_W=Soup.find_all('span' ,class_=\"table-body__logo-text\")\n",
    "Team_W=[]\n",
    "for t in team_W[0:9]:\n",
    "    Team_W.append(t.text.strip())\n",
    "    \n",
    "rating_W=Soup.find_all('td' ,class_=\"table-body__cell u-text-right rating\")\n",
    "Rating_W=[]\n",
    "for r in rating_W[0:9]:\n",
    "    Rating_W.append(r.text)\n",
    "\n",
    "DF_W=pd.DataFrame({'Player Name':Name_W,'Team':Team_W,'Rating':Rating_W})\n",
    "\n",
    "name1_W=Soup.find('div' ,class_=\"rankings-block__banner--name\")\n",
    "Name1_W=name1_W.text\n",
    "\n",
    "team1_W=Soup.find('div' ,class_=\"rankings-block__banner--nationality\")\n",
    "Team1_W=team1_W.text.replace('762','').strip()\n",
    "\n",
    "# rank1=Soup.find('div', class_=\"rankings-block__banner--pos\")\n",
    "# Rank1=rank1.text.replace('\\n','').strip()\n",
    "\n",
    "rating1_W=Soup.find('div' ,class_=\"rankings-block__banner--rating\")\n",
    "Rating1_W=rating1_W.text\n",
    "\n",
    "d_W={'Player Name':[Name1_W],'Team':[Team1_W],'Rating':[Rating1_W]}\n",
    "df_W=pd.DataFrame(data=d_W)\n",
    "new_df_W=pd.concat([df_W,DF_W])\n",
    "new_df_W.set_index('Player Name',inplace=True)\n",
    "new_df_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Marizanne Kapp</th>\n",
       "      <td>418</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ellyse Perry</th>\n",
       "      <td>418</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stafanie Taylor</th>\n",
       "      <td>394</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natalie Sciver</th>\n",
       "      <td>365</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deepti Sharma</th>\n",
       "      <td>331</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jess Jonassen</th>\n",
       "      <td>307</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ashleigh Gardner</th>\n",
       "      <td>252</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dane van Niekerk</th>\n",
       "      <td>243</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sophie Devine</th>\n",
       "      <td>242</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Katherine Brunt</th>\n",
       "      <td>239</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Rating Team\n",
       "Player Name                 \n",
       "Marizanne Kapp      418   SA\n",
       "Ellyse Perry        418  AUS\n",
       "Stafanie Taylor     394   WI\n",
       "Natalie Sciver      365  ENG\n",
       "Deepti Sharma       331  IND\n",
       "Jess Jonassen       307  AUS\n",
       "Ashleigh Gardner    252  AUS\n",
       "Dane van Niekerk    243   SA\n",
       "Sophie Devine       242   NZ\n",
       "Katherine Brunt     239  ENG"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ques_6\n",
    "#3.0\n",
    "\n",
    "#odi bowling ranking\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "page_AW=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page_AW\n",
    "page_AW.content\n",
    "Soup=BeautifulSoup(page_AW.content)\n",
    "Soup.prettify\n",
    "\n",
    "table_AW=Soup.find_all('td', class_=\"table-body__cell name\")\n",
    "Name_AW=[]\n",
    "for n in table_AW[18:27]:\n",
    "    for j in n.find_all('a'):\n",
    "        Name_AW.append(j.text.replace('\\n',''))\n",
    "\n",
    "team_AW=Soup.find_all('span' ,class_=\"table-body__logo-text\")\n",
    "Team_AW=[]\n",
    "for t in team_AW[18:27]:\n",
    "    Team_AW.append(t.text.strip())\n",
    "    \n",
    "rating_AW=Soup.find_all('td' ,class_=\"table-body__cell u-text-right rating\")\n",
    "Rating_AW=[]\n",
    "for r in rating_AW[18:27]:\n",
    "    Rating_AW.append(r.text)\n",
    "\n",
    "DF_AW=pd.DataFrame({'Player Name':Name_AW,'Team':Team_AW,'Rating':Rating_AW})\n",
    "\n",
    "Name1_AW=Soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "Name_1_AW=Name1_AW[2].text\n",
    "\n",
    "Team1_AW=Soup.find_all('div' ,class_=\"rankings-block__banner--nationality\")\n",
    "Team_1_AW=Team1_AW[2].text.replace('\\n','').split()[0]\n",
    "\n",
    "Rating1_AW=Soup.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "Rating_1_AW=Rating1_AW[2].text.replace('\\n','')\n",
    "\n",
    "d_AW={'Player Name':[Name_1_AW],'Team':[Team_1_AW],'Rating':[Rating_1_AW]}\n",
    "df_AW=pd.DataFrame(data=d_AW)\n",
    "new_df_AW=pd.concat([df_AW,DF_AW])\n",
    "new_df_AW.set_index('Player Name',inplace=True)\n",
    "\n",
    "new_df_AW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Image URL</th>\n",
       "      <th>Average Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Samsung Galaxy M31s (Mirage Blue, 8GB RAM, 128GB Storage) 6 Months Free Screen Replacement for Prime</th>\n",
       "      <td>₹14,999.00</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61d-phh4Gf...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB Storage)</th>\n",
       "      <td>₹19,999.00</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery</th>\n",
       "      <td>₹16,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2.3GHz Mediatek Helio G35 Octa core Processor</th>\n",
       "      <td>₹24,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realme C11 (2021) (Cool Blue, 2GB RAM, 32GB Storage) with No Cost EMI/Additional Exchange Offers</th>\n",
       "      <td>₹14,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71FYSKYFup...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samsung Galaxy M31 (Space Black, 6GB RAM, 128GB Storage)</th>\n",
       "      <td>₹19,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71OxJeyywS...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Storage) - 6000mAh Battery |FHD+ Screen| 48MP Quad Camera | Snapdragon 662 Processor | Alexa Hands-Free Capable</th>\n",
       "      <td>₹6,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61LHaUOheh...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi Note 10 (Shadow Black, 4GB RAM, 64GB Storage) - Amoled Dot Display | 48MP Sony Sensor IMX582 | Snapdragon 678 Processor</th>\n",
       "      <td>₹8,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81vixbGM2E...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samsung Galaxy M02s (Black,4GB RAM, 64GB Storage) | 5000 mAh | Triple Camera</th>\n",
       "      <td>₹8,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71IkA3T7hI...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi Note 10 Pro Max (Dark Night, 6GB RAM, 128GB Storage) -108MP Quad Camera | 120Hz Super Amoled Display</th>\n",
       "      <td>₹10,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81Vpy0XrvF...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oppo F19 (Prism Black, 6GB RAM, 128GB Storage) - 6.43\" Inch AMOLED Punch-Hole Display | in-Display Fingerprint 3.0 | 5000 mAh Battery | 33W Flash Charging</th>\n",
       "      <td>₹6,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71crCF+ogw...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mi 11X Pro 5G (Lunar White, 8GB RAM, 128GB Storage) | Snapdragon 888 | 108MP Camera | 6 Month Free Screen Replacement for Prime | Additional 5000 Off on Exchange</th>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71+g+SNcIL...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi 9A (Midnight Black, 2GB RAM, 32GB Storage) | 2GHz Octa-Core Helio G25 Processor</th>\n",
       "      <td>₹14,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage) with No Cost EMI/Additional Exchange Offers</th>\n",
       "      <td>₹19,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61CnyJ-IbM...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redmi Note 10 Pro (Glacial Blue, 6GB RAM, 128GB Storage) -120hz Super Amoled Display|64MP with 5mp Super Tele- Macro | Additional 1000 Off on Exchange</th>\n",
       "      <td>₹13,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81nndQAg2n...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Price  \\\n",
       "Product Name                                                     \n",
       "Samsung Galaxy M31s (Mirage Blue, 8GB RAM, 128G...  ₹14,999.00   \n",
       "Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB ...  ₹19,999.00   \n",
       "Redmi 9A (Nature Green, 2GB RAM, 32GB Storage) ...     ₹16,999   \n",
       "Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2.3...     ₹24,999   \n",
       "realme C11 (2021) (Cool Blue, 2GB RAM, 32GB Sto...     ₹14,999   \n",
       "Samsung Galaxy M31 (Space Black, 6GB RAM, 128GB...     ₹19,999   \n",
       "Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Sto...      ₹6,999   \n",
       "Redmi Note 10 (Shadow Black, 4GB RAM, 64GB Stor...      ₹8,499   \n",
       "Samsung Galaxy M02s (Black,4GB RAM, 64GB Storag...      ₹8,999   \n",
       "Redmi Note 10 Pro Max (Dark Night, 6GB RAM, 128...     ₹10,999   \n",
       "Oppo F19 (Prism Black, 6GB RAM, 128GB Storage) ...      ₹6,999   \n",
       "Mi 11X Pro 5G (Lunar White, 8GB RAM, 128GB Stor...      ₹7,999   \n",
       "Redmi 9A (Midnight Black, 2GB RAM, 32GB Storage...     ₹14,999   \n",
       "Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage...     ₹19,999   \n",
       "Redmi Note 10 Pro (Glacial Blue, 6GB RAM, 128GB...     ₹13,499   \n",
       "\n",
       "                                                                                            Image URL  \\\n",
       "Product Name                                                                                            \n",
       "Samsung Galaxy M31s (Mirage Blue, 8GB RAM, 128G...  https://m.media-amazon.com/images/I/61d-phh4Gf...   \n",
       "Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB ...  https://m.media-amazon.com/images/I/71-Su4Wr0H...   \n",
       "Redmi 9A (Nature Green, 2GB RAM, 32GB Storage) ...  https://m.media-amazon.com/images/I/71sxlhYhKW...   \n",
       "Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2.3...  https://m.media-amazon.com/images/I/71A9Vo1Bat...   \n",
       "realme C11 (2021) (Cool Blue, 2GB RAM, 32GB Sto...  https://m.media-amazon.com/images/I/71FYSKYFup...   \n",
       "Samsung Galaxy M31 (Space Black, 6GB RAM, 128GB...  https://m.media-amazon.com/images/I/71OxJeyywS...   \n",
       "Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Sto...  https://m.media-amazon.com/images/I/61LHaUOheh...   \n",
       "Redmi Note 10 (Shadow Black, 4GB RAM, 64GB Stor...  https://m.media-amazon.com/images/I/81vixbGM2E...   \n",
       "Samsung Galaxy M02s (Black,4GB RAM, 64GB Storag...  https://m.media-amazon.com/images/I/71IkA3T7hI...   \n",
       "Redmi Note 10 Pro Max (Dark Night, 6GB RAM, 128...  https://m.media-amazon.com/images/I/81Vpy0XrvF...   \n",
       "Oppo F19 (Prism Black, 6GB RAM, 128GB Storage) ...  https://m.media-amazon.com/images/I/71crCF+ogw...   \n",
       "Mi 11X Pro 5G (Lunar White, 8GB RAM, 128GB Stor...  https://m.media-amazon.com/images/I/71+g+SNcIL...   \n",
       "Redmi 9A (Midnight Black, 2GB RAM, 32GB Storage...  https://m.media-amazon.com/images/I/71sxlhYhKW...   \n",
       "Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage...  https://m.media-amazon.com/images/I/61CnyJ-IbM...   \n",
       "Redmi Note 10 Pro (Glacial Blue, 6GB RAM, 128GB...  https://m.media-amazon.com/images/I/81nndQAg2n...   \n",
       "\n",
       "                                                        Average Rating  \n",
       "Product Name                                                            \n",
       "Samsung Galaxy M31s (Mirage Blue, 8GB RAM, 128G...  4.2 out of 5 stars  \n",
       "Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB ...  4.2 out of 5 stars  \n",
       "Redmi 9A (Nature Green, 2GB RAM, 32GB Storage) ...  4.1 out of 5 stars  \n",
       "Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage) | 2.3...  4.2 out of 5 stars  \n",
       "realme C11 (2021) (Cool Blue, 2GB RAM, 32GB Sto...  4.1 out of 5 stars  \n",
       "Samsung Galaxy M31 (Space Black, 6GB RAM, 128GB...  4.1 out of 5 stars  \n",
       "Redmi 9 Power (Mighty Black, 6GB RAM, 128GB Sto...  4.1 out of 5 stars  \n",
       "Redmi Note 10 (Shadow Black, 4GB RAM, 64GB Stor...  4.1 out of 5 stars  \n",
       "Samsung Galaxy M02s (Black,4GB RAM, 64GB Storag...  3.9 out of 5 stars  \n",
       "Redmi Note 10 Pro Max (Dark Night, 6GB RAM, 128...  4.2 out of 5 stars  \n",
       "Oppo F19 (Prism Black, 6GB RAM, 128GB Storage) ...  4.2 out of 5 stars  \n",
       "Mi 11X Pro 5G (Lunar White, 8GB RAM, 128GB Stor...  4.2 out of 5 stars  \n",
       "Redmi 9A (Midnight Black, 2GB RAM, 32GB Storage...  4.0 out of 5 stars  \n",
       "Oppo A31 (Fantasy White, 6GB RAM, 128GB Storage...  4.0 out of 5 stars  \n",
       "Redmi Note 10 Pro (Glacial Blue, 6GB RAM, 128GB...  4.0 out of 5 stars  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data \n",
    "#should include Product Name, Price, Image URL and Average Rating.\n",
    "\n",
    "#Ques_7\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "HEADERS = ({'User-Agent':\n",
    "            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \\\n",
    "            (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\\\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "\n",
    "url_1=requests.get('https://www.amazon.in/s?k=mobile+under+20000&ref=nb_sb_noss_1',headers=HEADERS)\n",
    "Soup=BeautifulSoup(url_1.content)\n",
    "Soup.prettify()\n",
    "\n",
    "# soup2 = BeautifulSoup(url_1.content, \"html.parser\")\n",
    "# dom = etree.HTML(str(soup2))\n",
    "# print(dom.xpath('//*[@id=\"search\"]/div[1]/div[1]/div/span[3]/div[2]/div[1]/div/span/div/div/div/div/div[2]/div[2]/div/div/div[3]/div[1]/div/div[1]/div[2]/a/span[1]/span[2]/span[2]'))\n",
    "\n",
    "product_name=Soup.find_all('h2', class_=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\")\n",
    "Product_name=[]\n",
    "for p in product_name:\n",
    "    for j in p.find_all('a'):\n",
    "        Product_name.append(j.text.strip())\n",
    "Product_name\n",
    "\n",
    "price_item=Soup.find_all('span' ,class_=\"a-offscreen\")\n",
    "Price_item=[]\n",
    "for t in price_item:\n",
    "    Price_item.append(t.text)\n",
    "Price_item\n",
    "\n",
    "average_rating=Soup.find_all('i' ,class_=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\")\n",
    "Average_rating=[]\n",
    "for a in average_rating[0:15]:\n",
    "    Average_rating.append(a.text)\n",
    "Average_rating\n",
    "\n",
    "image_url=Soup.find_all('img' ,class_=\"s-image\")\n",
    "Image_url=[]\n",
    "for a in image_url:\n",
    "    Image_url.append(a.attrs['src'])\n",
    "\n",
    "pd=pd.DataFrame({})\n",
    "pd['Product Name']=Product_name[:15]\n",
    "pd['Price']=Price_item[:15]\n",
    "pd['Image URL']=Image_url[:15]\n",
    "pd['Average Rating']=Average_rating[:15]\n",
    "pd.set_index('Product Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>Sunny thenHaze</td>\n",
       "      <td>High: 76 °F</td>\n",
       "      <td>Widespread haze between 1pm and 5pm. Areas of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tonight</th>\n",
       "      <td>Haze andBreezy</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Widespread haze before 5am. Areas of smoke bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>Haze</td>\n",
       "      <td>High: 77 °F</td>\n",
       "      <td>Widespread haze before 3pm. Sunny, with a high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaturdayNight</th>\n",
       "      <td>Mostly Clearand Breezythen MostlyClear</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Mostly clear, with a low around 57. Breezy, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 73 °F</td>\n",
       "      <td>Sunny, with a high near 73. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SundayNight</th>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "      <td>Mostly clear, with a low around 56. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 68 °F</td>\n",
       "      <td>Mostly sunny, with a high near 68.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MondayNight</th>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 55 °F</td>\n",
       "      <td>Mostly clear, with a low around 55.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 66 °F</td>\n",
       "      <td>Sunny, with a high near 66.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Short Description  Temperature  \\\n",
       "Period                                                                \n",
       "Today                                   Sunny thenHaze  High: 76 °F   \n",
       "Tonight                                 Haze andBreezy   Low: 58 °F   \n",
       "Saturday                                          Haze  High: 77 °F   \n",
       "SaturdayNight   Mostly Clearand Breezythen MostlyClear   Low: 57 °F   \n",
       "Sunday                Mostly Sunnythen Sunnyand Breezy  High: 73 °F   \n",
       "SundayNight    Mostly Clearand Breezythen PartlyCloudy   Low: 56 °F   \n",
       "Monday                                    Mostly Sunny  High: 68 °F   \n",
       "MondayNight                               Mostly Clear   Low: 55 °F   \n",
       "Tuesday                                          Sunny  High: 66 °F   \n",
       "\n",
       "                                                     Description  \n",
       "Period                                                            \n",
       "Today          Widespread haze between 1pm and 5pm. Areas of ...  \n",
       "Tonight        Widespread haze before 5am. Areas of smoke bef...  \n",
       "Saturday       Widespread haze before 3pm. Sunny, with a high...  \n",
       "SaturdayNight  Mostly clear, with a low around 57. Breezy, wi...  \n",
       "Sunday         Sunny, with a high near 73. Breezy, with a wes...  \n",
       "SundayNight          Mostly clear, with a low around 56. Breezy.  \n",
       "Monday                        Mostly sunny, with a high near 68.  \n",
       "MondayNight                  Mostly clear, with a low around 55.  \n",
       "Tuesday                              Sunny, with a high near 66.  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to extract information about the local weather from the National Weather Service website of USA, \n",
    "#https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the\n",
    "#city. The data should include period, short description, temperature and description.\n",
    "\n",
    "#Ques_8\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url2=requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YR_iS4gzbIU')\n",
    "Soup=BeautifulSoup(url2.content)\n",
    "Soup.prettify\n",
    "period=Soup.find_all('p', class_=\"period-name\")\n",
    "Period=[]\n",
    "for p in period:\n",
    "    Period.append(p.text.replace('\\n',''))\n",
    "Period\n",
    "\n",
    "short_d=Soup.find_all('p' ,class_=\"short-desc\")\n",
    "Short_d=[]\n",
    "for s in short_d:\n",
    "    Short_d.append(s.text)\n",
    "Short_d\n",
    "\n",
    "temp=Soup.find_all('p', class_=\"temp\")\n",
    "Temp=[]\n",
    "for t in temp:\n",
    "    Temp.append(t.text)\n",
    "\n",
    "desc=Soup.find_all('div', class_=\"col-sm-10 forecast-text\")\n",
    "Desc=[]\n",
    "for d in desc:\n",
    "    Desc.append(d.text.strip())\n",
    "Desc\n",
    "\n",
    "df=pd.DataFrame({})\n",
    "df['Period']=Period[:10]\n",
    "df['Short Description']=Short_d[:10]\n",
    "df['Temperature']=Temp[:10]\n",
    "df['Description']=Desc[:9]\n",
    "df.set_index('Period')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OMNI SPORT LEADER</th>\n",
       "      <td>Decathlon Sport India Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>Apply By18 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Executive/Senior Executive - Partnerships</th>\n",
       "      <td>Freecharge Payments Technology Private Limited</td>\n",
       "      <td>3 - 4.2 LPA</td>\n",
       "      <td>Apply By11 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Executive - Sales</th>\n",
       "      <td>Freecharge Payments Technology Private Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>Apply By11 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junior Operations Executive</th>\n",
       "      <td>Freecharge Payments Technology Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>Apply By4 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales Executive</th>\n",
       "      <td>Hedge Homes</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>Apply By26 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organizational Behavior Specialist</th>\n",
       "      <td>SysCloud Technologies Private Limited</td>\n",
       "      <td>4.5 - 6 LPA</td>\n",
       "      <td>Apply By26 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Online Sales Executive</th>\n",
       "      <td>Intesome</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>Apply By26 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital Marketing Specialist</th>\n",
       "      <td>Ohana Academy</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>Apply By26 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buddy Counselor (Study Abroad)</th>\n",
       "      <td>UniAcco</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>Apply By26 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student Success - Teacher</th>\n",
       "      <td>Code A Block (KEDTech LLC)</td>\n",
       "      <td>4 - 7.2 LPA</td>\n",
       "      <td>Apply By25 Sep' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             Company Name  \\\n",
       "Job Title                                                                                   \n",
       "OMNI SPORT LEADER                                   Decathlon Sport India Private Limited   \n",
       "Executive/Senior Executive - Partnerships  Freecharge Payments Technology Private Limited   \n",
       "Executive - Sales                          Freecharge Payments Technology Private Limited   \n",
       "Junior Operations Executive                Freecharge Payments Technology Private Limited   \n",
       "Sales Executive                                                               Hedge Homes   \n",
       "Organizational Behavior Specialist                  SysCloud Technologies Private Limited   \n",
       "International Online Sales Executive                                             Intesome   \n",
       "Digital Marketing Specialist                                                Ohana Academy   \n",
       "Buddy Counselor (Study Abroad)                                                    UniAcco   \n",
       "Student Success - Teacher                                      Code A Block (KEDTech LLC)   \n",
       "\n",
       "                                                   CTC          Apply Date  \n",
       "Job Title                                                                   \n",
       "OMNI SPORT LEADER                            3 - 4 LPA  Apply By18 Sep' 21  \n",
       "Executive/Senior Executive - Partnerships  3 - 4.2 LPA  Apply By11 Sep' 21  \n",
       "Executive - Sales                          3 - 3.5 LPA  Apply By11 Sep' 21  \n",
       "Junior Operations Executive                  3 - 4 LPA   Apply By4 Sep' 21  \n",
       "Sales Executive                            3 - 3.5 LPA  Apply By26 Sep' 21  \n",
       "Organizational Behavior Specialist         4.5 - 6 LPA  Apply By26 Sep' 21  \n",
       "International Online Sales Executive         3 - 4 LPA  Apply By26 Sep' 21  \n",
       "Digital Marketing Specialist                 3 - 5 LPA  Apply By26 Sep' 21  \n",
       "Buddy Counselor (Study Abroad)               3 - 5 LPA  Apply By26 Sep' 21  \n",
       "Student Success - Teacher                  4 - 7.2 LPA  Apply By25 Sep' 21  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company \n",
    "#name, CTC, and apply date.\n",
    "\n",
    "#Ques_9\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "url2=requests.get('https://internshala.com/fresher-jobs')\n",
    "url2\n",
    "Soup=BeautifulSoup(url2.content)\n",
    "Soup.prettify\n",
    "\n",
    "title=Soup.find_all('div' ,class_=\"heading_4_5 profile\")\n",
    "Title=[]\n",
    "for t in title:\n",
    "    for i in t.find_all('a'):\n",
    "        Title.append(i.text.replace('\\n',''))\n",
    "# Title\n",
    "\n",
    "name=Soup.find_all('div', class_=\"heading_6 company_name\")\n",
    "Name=[]\n",
    "for n in name:\n",
    "    Name.append(n.text.replace('\\n','').strip())\n",
    "# Name\n",
    "\n",
    "ctc=Soup.find_all('div' ,class_=\"item_body\")\n",
    "CTC=[]\n",
    "for c in ctc:\n",
    "    if c.text.replace('\\n','').strip().endswith('LPA'):\n",
    "        CTC.append(c.text.replace('\\n','').strip())\n",
    "# CTC\n",
    "\n",
    "applydate=Soup.find_all('div', class_=\"other_detail_item_row\")\n",
    "Apply=[]\n",
    "for a in applydate:\n",
    "    if a.text.replace('\\n','').strip().startswith('Apply'):\n",
    "        Apply.append(a.text.replace('\\n','').strip())\n",
    "# Apply\n",
    "\n",
    "D2=pd.DataFrame({})\n",
    "D2['Job Title']=Title[0:10]\n",
    "D2['Company Name']=Name[:10]\n",
    "D2['CTC']=CTC[:10]\n",
    "D2['Apply Date']=Apply[:10]\n",
    "D2.set_index('Job Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file E:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2 BHK Flat  For Sale  In  Agarwal Complex , Galaxy  In Vasai West</th>\n",
       "      <td>910 sqft</td>\n",
       "      <td>₹44,705/Month</td>\n",
       "      <td>Near Macdonald, near kauls heritage</td>\n",
       "      <td>₹78 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Area            EMI  \\\n",
       "Title                                                                         \n",
       "2 BHK Flat  For Sale  In  Agarwal Complex , Gal...  910 sqft  ₹44,705/Month   \n",
       "\n",
       "                                                                                Location  \\\n",
       "Title                                                                                      \n",
       "2 BHK Flat  For Sale  In  Agarwal Complex , Gal...  Near Macdonald, near kauls heritage    \n",
       "\n",
       "                                                       Price  \n",
       "Title                                                         \n",
       "2 BHK Flat  For Sale  In  Agarwal Complex , Gal...  ₹78 Lacs  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, \n",
    "#location, area, emi and price\n",
    "\n",
    "#Ques_10\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url3=requests.get('https://www.nobroker.in/property/sale/mumbai/Vasai%20West?searchParam=W3sibGF0IjoxOS4zNjY0NjMxLCJsb24iOjcyLjgxNTUxMzYsInBsYWNlSWQiOiJDaElKWVp6dnVpcXM1enNSREU4b0ZhdVdJbEEiLCJwbGFjZU5hbWUiOiJWYXNhaSBXZXN0In1d&radius=2.0&type=BHK2&propertyAge=0')\n",
    "url3\n",
    "Soup=BeautifulSoup(url3.content)\n",
    "Soup.prettify\n",
    "\n",
    "title=Soup.find('h2', class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "Title=title.text.strip()\n",
    "\n",
    "location=Soup.find('div', class_=\"nb__2CMjv\")\n",
    "Location=location.text\n",
    "\n",
    "area=Soup.find('div', class_=\"font-semi-bold heading-6\",id='minRent')\n",
    "Area=area.text\n",
    "\n",
    "emi=Soup.find('div' ,class_=\"font-semi-bold heading-6\", id='roomType')\n",
    "EMI=emi.text\n",
    "\n",
    "price=Soup.find('div', class_=\"font-semi-bold heading-6\",id='')\n",
    "Price=price.text\n",
    "\n",
    "D1=pd.DataFrame({'Title':[Title],'Location':[Location],'Area':[Area],'EMI':[EMI],'Price':[Price]})\n",
    "\n",
    "D1.set_index('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
